{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d21c489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libaires\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from pathlib import Path\n",
    "\n",
    "# Load project configuration\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Extract paths\n",
    "data_raw = Path(config['paths']['data_raw'])\n",
    "data_processed = Path(config['paths']['data_processed'])\n",
    "climate_path = Path(config['paths']['climate'])\n",
    "socialvulnerability_path = Path(config['paths']['socialvulnerability'])\n",
    "infrastructure_path = Path(config['paths']['infrastructure'])\n",
    "shapefiles_path = Path(config['paths']['shapefiles'])\n",
    "redlining_path = Path(config['paths']['redlining'])\n",
    "Outputs_path = Path(config['paths']['outputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b9e0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "class Config:\n",
    "    GEOCODE_CACHE = 'geocode_cache.json'\n",
    "    OUTPUT_MAP = Outputs_path / 'Figures' / 'nyc_infrastructure_access.png'\n",
    "    WEIGHTS = {'height': 0.25, 'age': 0.25, 'area': 0.25, 'elevation': 0.25}\n",
    "\n",
    "def calculate_heat_index(gdf):\n",
    "    score = pd.Series(0.0, index=gdf.index)\n",
    "    if 'Height_Roof' in gdf.columns:\n",
    "        height = pd.to_numeric(gdf['Height_Roof'], errors='coerce').fillna(0)\n",
    "        score += (height / 100).clip(0, 1) * Config.WEIGHTS['height'] * 100\n",
    "    if 'Construction_Year' in gdf.columns:\n",
    "        year = pd.to_numeric(gdf['Construction_Year'], errors='coerce').fillna(2026)\n",
    "        age = 2026 - year\n",
    "        score += (age / 100).clip(0, 1) * Config.WEIGHTS['age'] * 100\n",
    "    if 'SHAPE_AREA' in gdf.columns:\n",
    "        area = pd.to_numeric(gdf['SHAPE_AREA'], errors='coerce').fillna(0)\n",
    "        score += (area / 500).clip(0, 1) * Config.WEIGHTS['area'] * 100\n",
    "    if 'Ground_Elevation' in gdf.columns:\n",
    "        elev_data = pd.to_numeric(gdf['Ground_Elevation'], errors='coerce').fillna(100)\n",
    "        elev = (1 - (elev_data / 200)).clip(0, 1)\n",
    "        score += elev * Config.WEIGHTS['elevation'] * 100\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3ce8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEOCODING WITH CACHE (ADDRESS TO LAT/LON)\n",
    "\n",
    "def get_geocoder():\n",
    "    geolocator = Nominatim(\n",
    "        user_agent=\"nyc_heat\",\n",
    "        timeout=10\n",
    "    )\n",
    "\n",
    "    return RateLimiter(\n",
    "        geolocator.geocode,\n",
    "        min_delay_seconds=2,\n",
    "        max_retries=3,\n",
    "        error_wait_seconds=5,\n",
    "        swallow_exceptions=True\n",
    "    )\n",
    "\n",
    "\n",
    "def geocode_with_cache(df, address_col='Address', borough_col='Borough'):\n",
    "\n",
    "    # Load cache\n",
    "    cache = {}\n",
    "    if os.path.exists(Config.GEOCODE_CACHE):\n",
    "        with open(Config.GEOCODE_CACHE, 'r') as f:\n",
    "            cache = json.load(f)\n",
    "\n",
    "    geocode = get_geocoder()\n",
    "\n",
    "    lats = []\n",
    "    lons = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        addr = f\"{row[address_col]}, {row[borough_col]}, NY\"\n",
    "\n",
    "        if addr in cache:\n",
    "            lat = cache[addr]['lat']\n",
    "            lon = cache[addr]['lon']\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                loc = geocode(addr)\n",
    "\n",
    "                if loc:\n",
    "                    lat = loc.latitude\n",
    "                    lon = loc.longitude\n",
    "\n",
    "                    cache[addr] = {\n",
    "                        'lat': lat,\n",
    "                        'lon': lon\n",
    "                    }\n",
    "\n",
    "                    # SAVE CACHE IMMEDIATELY (critical fix)\n",
    "                    with open(Config.GEOCODE_CACHE, 'w') as f:\n",
    "                        json.dump(cache, f)\n",
    "\n",
    "                else:\n",
    "                    lat, lon = None, None\n",
    "\n",
    "            except Exception:\n",
    "                lat, lon = None, None\n",
    "\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "\n",
    "    df['latitude'] = lats\n",
    "    df['longitude'] = lons\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3957b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading outdoor cooling centers...\n",
      "Loading green infrastructure...\n",
      "Loading urban design data...\n",
      "Loading neighborhood boundaries...\n",
      "Aggregating heat index to neighborhood level...\n",
      "\n",
      "=== ANALYSIS OF INVALID/OUTLIER ADDRESSES ===\n",
      "\n",
      "Panel 1 saved\n",
      "Panel 2 saved\n",
      "Panel 3 saved\n",
      "\n",
      "✓ Analysis complete. All maps saved to c:\\Users\\Jackson\\OneDrive\\Desktop\\APRESPRO\\Outputs\\Figures\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # 1. Load Indoor Centers and create point geometries (do NOT attempt geocoding here)\n",
    "        df_in = pd.read_csv(data_processed / 'inside_cooling_centers_final.csv')\n",
    "\n",
    "        # Identify latitude/longitude-like columns in the indoor dataset\n",
    "        lat_cols_in = [c for c in df_in.columns if c.lower() in ['latitude', 'lat', 'y']]\n",
    "        lon_cols_in = [c for c in df_in.columns if c.lower() in ['longitude', 'lon', 'x']]\n",
    "\n",
    "        if lat_cols_in and lon_cols_in:\n",
    "            lat_col = lat_cols_in[0]\n",
    "            lon_col = lon_cols_in[0]\n",
    "            df_in[lat_col] = pd.to_numeric(df_in[lat_col], errors='coerce')\n",
    "            df_in[lon_col] = pd.to_numeric(df_in[lon_col], errors='coerce')\n",
    "            df_in_valid = df_in[df_in[lat_col].notna() & df_in[lon_col].notna() & np.isfinite(df_in[lat_col]) & np.isfinite(df_in[lon_col])].copy()\n",
    "            if not df_in_valid.empty:\n",
    "                gdf_in = gpd.GeoDataFrame(df_in_valid, geometry=gpd.points_from_xy(df_in_valid[lon_col], df_in_valid[lat_col]), crs=\"EPSG:4326\")\n",
    "                gdf_in['type'] = 'Indoor'\n",
    "            else:\n",
    "                gdf_in = gpd.GeoDataFrame(columns=list(df_in.columns) + ['geometry','type'], crs=\"EPSG:4326\")\n",
    "        else:\n",
    "            # No coordinate columns found — create empty GeoDataFrame\n",
    "            gdf_in = gpd.GeoDataFrame(columns=list(df_in.columns) + ['geometry','type'], crs=\"EPSG:4326\")\n",
    "\n",
    "        # 2. Load Outdoor Features\n",
    "        print(\"Loading outdoor cooling centers...\")\n",
    "        df_out = pd.read_csv(data_processed / 'outside_cooling_centers_final.csv')\n",
    "        # Detect coordinate-like columns for outdoor dataset\n",
    "        x_cols_out = [c for c in df_out.columns if c.lower() in ['x','lon','longitude']]\n",
    "        y_cols_out = [c for c in df_out.columns if c.lower() in ['y','lat','latitude']]\n",
    "        if x_cols_out and y_cols_out:\n",
    "            xcol = x_cols_out[0]\n",
    "            ycol = y_cols_out[0]\n",
    "            df_out[xcol] = pd.to_numeric(df_out[xcol].astype(str).str.replace(',', ''), errors='coerce')\n",
    "            df_out[ycol] = pd.to_numeric(df_out[ycol].astype(str).str.replace(',', ''), errors='coerce')\n",
    "            valid_out = df_out[df_out[xcol].notna() & df_out[ycol].notna() & np.isfinite(df_out[xcol]) & np.isfinite(df_out[ycol])].copy()\n",
    "            if not valid_out.empty:\n",
    "                gdf_out = gpd.GeoDataFrame(valid_out, geometry=gpd.points_from_xy(valid_out[xcol], valid_out[ycol]), crs=\"EPSG:4326\")\n",
    "                gdf_out['type'] = 'Outdoor'\n",
    "            else:\n",
    "                gdf_out = gpd.GeoDataFrame(columns=list(df_out.columns) + ['geometry','type'], crs=\"EPSG:4326\")\n",
    "        else:\n",
    "            gdf_out = gpd.GeoDataFrame(columns=list(df_out.columns) + ['geometry','type'], crs=\"EPSG:4326\")\n",
    "\n",
    "        # Check for coordinate outliers in outdoor centers (keep diagnostic if needed)\n",
    "        invalid_out = pd.DataFrame()\n",
    "        if 'xcol' in locals() and 'ycol' in locals():\n",
    "            invalid_out = df_out[~((df_out[xcol].notna()) & (df_out[ycol].notna()) & np.isfinite(df_out[xcol]) & np.isfinite(df_out[ycol]))]\n",
    "\n",
    "        # 3. Load Green Infrastructure\n",
    "        print(\"Loading green infrastructure...\")\n",
    "        df_green = pd.read_csv(data_processed / 'green_spaces_final.csv')\n",
    "        df_green['geometry'] = df_green['the_geom'].apply(wkt.loads)\n",
    "        gdf_green = gpd.GeoDataFrame(df_green, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "        # 4. Load Urban Design (Buildings)\n",
    "        print(\"Loading urban design data...\")\n",
    "        df_urban = pd.read_csv(data_processed / 'urban_design_final.csv', low_memory=False)\n",
    "        df_urban['geometry'] = df_urban['the_geom'].apply(wkt.loads)\n",
    "        gdf_urban = gpd.GeoDataFrame(df_urban, geometry='geometry', crs=\"EPSG:4326\")\n",
    "        gdf_urban['heat_index'] = calculate_heat_index(gdf_urban)\n",
    "\n",
    "        # 5. Load Neighborhoods for context and aggregation\n",
    "        print(\"Loading neighborhood boundaries...\")\n",
    "        neighborhoods = gpd.read_file(data_processed / 'neighborhoods_final.gpkg').to_crs(\"EPSG:4326\")\n",
    "\n",
    "        # 6. Aggregate heat index by neighborhood (prefer NTA/name fields, not borough)\n",
    "        print(\"Aggregating heat index to neighborhood level...\")\n",
    "        urban_with_neigh = gpd.sjoin(gdf_urban, neighborhoods, how=\"left\", predicate=\"within\")\n",
    "\n",
    "        def detect_neighborhood_key(df):\n",
    "            # Common NTA/name column candidates\n",
    "            preferred = ['nta_name', 'ntaname', 'nta', 'ntacode', 'ntaname20', 'ntaname_2020', 'name', 'label']\n",
    "            cols = [c for c in df.columns if isinstance(c, str)]\n",
    "            # try preferred list first\n",
    "            for p in preferred:\n",
    "                for c in cols:\n",
    "                    if p in c.lower():\n",
    "                        return c\n",
    "            # fallback: any column that contains 'nta' or 'name' but not 'borough'\n",
    "            candidates = [c for c in cols if ('nta' in c.lower() or 'name' in c.lower()) and 'borough' not in c.lower()]\n",
    "            if candidates:\n",
    "                return candidates[0]\n",
    "            # last resort: first non-geometry string column\n",
    "            for c in cols:\n",
    "                if c != df.geometry.name:\n",
    "                    return c\n",
    "            return df.index.name or 'index'\n",
    "\n",
    "        neigh_col = detect_neighborhood_key(neighborhoods)\n",
    "        neigh_heat = urban_with_neigh.groupby(neigh_col)['heat_index'].agg(['mean', 'count']).reset_index()\n",
    "        neighborhoods_heat = neighborhoods.merge(neigh_heat, on=neigh_col, how='left')\n",
    "        neighborhoods_heat['mean'] = neighborhoods_heat['mean'].fillna(0)\n",
    "        neighborhoods_heat['count'] = neighborhoods_heat['count'].fillna(0)\n",
    "\n",
    "        # 7. Optionally record invalid/outlier coordinates for review\n",
    "        print(\"\\n=== ANALYSIS OF INVALID/OUTLIER ADDRESSES ===\\n\")\n",
    "        invalid_analysis = []\n",
    "        if not invalid_out.empty:\n",
    "            print(f\"OUTDOOR COOLING CENTERS - INVALID COORDINATES ({len(invalid_out)} addresses):\")\n",
    "            for idx, row in invalid_out.iterrows():\n",
    "                x_val = row.get(xcol) if 'xcol' in locals() else row.get('x', None)\n",
    "                y_val = row.get(ycol) if 'ycol' in locals() else row.get('y', None)\n",
    "                issue = 'NaN/Missing coordinates' if pd.isna(x_val) or pd.isna(y_val) else 'Non-finite/Invalid'\n",
    "                invalid_analysis.append({\n",
    "                    'Name': row.get('name', 'N/A'),\n",
    "                    'Borough': row.get('Borough', 'N/A'),\n",
    "                    'X': x_val,\n",
    "                    'Y': y_val,\n",
    "                    'Issue': issue,\n",
    "                    'Category': 'Invalid Coordinates',\n",
    "                })\n",
    "        if invalid_analysis:\n",
    "            pd.DataFrame(invalid_analysis).to_csv(data_processed / 'all_invalid_missing_addresses.csv', index=False)\n",
    "            print(f\"Saved complete analysis to: {data_processed / 'all_invalid_missing_addresses.csv'}\")\n",
    "\n",
    "        # Combine indoor and outdoor into a single cooling GeoDataFrame and keep only points inside neighborhoods\n",
    "        gdf_cooling = pd.concat([gdf_in, gdf_out], ignore_index=True, sort=False)\n",
    "        # Ensure valid geometries\n",
    "        if not gdf_cooling.empty:\n",
    "            gdf_cooling = gdf_cooling[gdf_cooling.geometry.notna() & gdf_cooling.geometry.is_valid].copy()\n",
    "            # spatial join to neighborhoods: keep only points within neighborhood polygons\n",
    "            gdf_cooling = gpd.sjoin(gdf_cooling, neighborhoods.reset_index(), how='left', predicate='within')\n",
    "            # drop points that did not join to any neighborhood\n",
    "            if 'index' in gdf_cooling.columns:\n",
    "                gdf_cooling = gdf_cooling[gdf_cooling['index'].notna()]\n",
    "            gdf_cooling = gdf_cooling.set_geometry('geometry')\n",
    "\n",
    "        gdf_green_valid = gdf_green[gdf_green.geometry.is_valid] if not gdf_green.empty else gdf_green\n",
    "\n",
    "        # PANEL 1: Cooling Infrastructure Access (Full NYC) — plot Indoor and Outdoor in different colors\n",
    "        fig1, ax1 = plt.subplots(1, 1, figsize=(14, 14))\n",
    "        neighborhoods.plot(ax=ax1, color='whitesmoke', edgecolor='black', linewidth=0.5)\n",
    "        if not gdf_cooling.empty:\n",
    "            indoor_pts = gdf_cooling[gdf_cooling['type'] == 'Indoor'] if 'type' in gdf_cooling.columns else gdf_cooling.iloc[0:0]\n",
    "            outdoor_pts = gdf_cooling[gdf_cooling['type'] == 'Outdoor'] if 'type' in gdf_cooling.columns else gdf_cooling.iloc[0:0]\n",
    "            if not indoor_pts.empty:\n",
    "                indoor_pts.plot(ax=ax1, color='blue', markersize=10, label='Indoor', alpha=0.85)\n",
    "            if not outdoor_pts.empty:\n",
    "                outdoor_pts.plot(ax=ax1, color='cyan', markersize=6, label='Outdoor', alpha=0.8)\n",
    "\n",
    "        ax1.set_title(\"Cooling Infrastructure Access - All of NYC\", fontsize=16, pad=10, weight='bold')\n",
    "        ax1.legend(loc='upper right', fontsize=12)\n",
    "        ax1.axis('off')\n",
    "        plt.tight_layout()\n",
    "        panel1_path = Outputs_path / 'Figures' / 'panel1_cooling_infrastructure.png'\n",
    "        panel1_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(panel1_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Panel 1 saved\")\n",
    "\n",
    "        # PANEL 2: Green Infrastructure (Reduced visibility)\n",
    "        fig2, ax2 = plt.subplots(1, 1, figsize=(14, 14))\n",
    "        neighborhoods.plot(ax=ax2, color='whitesmoke', edgecolor='black', linewidth=0.5)\n",
    "        if not gdf_green_valid.empty:\n",
    "            gdf_green_valid.plot(ax=ax2, color='green', markersize=3, alpha=0.4)\n",
    "        ax2.set_title(\"Nature-Based Solutions (NbS)\", fontsize=16, pad=10, weight='bold')\n",
    "        ax2.axis('off')\n",
    "        plt.tight_layout()\n",
    "        panel2_path = Outputs_path / 'Figures' / 'panel2_green_infrastructure.png'\n",
    "        plt.savefig(panel2_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Panel 2 saved\")\n",
    "\n",
    "        # PANEL 3: Heat Vulnerability (Neighborhoods colored by heat index) - quantile bins per neighborhood\n",
    "        fig3, ax3 = plt.subplots(1, 1, figsize=(14, 14))\n",
    "\n",
    "        vals = neighborhoods_heat['mean'].astype(float)\n",
    "        if vals.nunique() > 1:\n",
    "            # create 5 quantile bins to increase sensitivity to local variation\n",
    "            q = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "            bins = list(vals.quantile(q).values)\n",
    "            # Ensure bins are strictly increasing\n",
    "            bins = sorted(list(dict.fromkeys(bins)))\n",
    "            if len(bins) < 2:\n",
    "                bins = [vals.min(), vals.max()]\n",
    "            neighborhoods_heat['heat_bin'] = pd.cut(vals, bins=bins, include_lowest=True, labels=False)\n",
    "            n_bins = int(neighborhoods_heat['heat_bin'].max()) + 1\n",
    "            cmap = plt.cm.get_cmap('YlOrRd', max(2, n_bins))\n",
    "            neighborhoods_heat.plot(column='heat_bin', ax=ax3, cmap=cmap, categorical=True, edgecolor='black', linewidth=0.3, legend=False)\n",
    "\n",
    "            # create legend patches showing bin ranges\n",
    "            import matplotlib.patches as mpatches\n",
    "            patches = []\n",
    "            bin_edges = bins\n",
    "            denom = max(1, len(bin_edges)-2)\n",
    "            for i in range(len(bin_edges)-1):\n",
    "                low = bin_edges[i]\n",
    "                high = bin_edges[i+1]\n",
    "                color = cmap(i/denom)\n",
    "                label = f\"{low:.1f} – {high:.1f}\"\n",
    "                patches.append(mpatches.Patch(color=color, label=label))\n",
    "            ax3.legend(handles=patches, title='Mean Heat Index (quantile bins)', loc='lower left', fontsize=10)\n",
    "        else:\n",
    "            neighborhoods_heat.plot(column='mean', ax=ax3, cmap='YlOrRd', edgecolor='black', linewidth=0.3, legend=True)\n",
    "\n",
    "        ax3.set_title(\"Urban Design Heat Vulnerability by Neighborhood\", fontsize=16, pad=10, weight='bold')\n",
    "        ax3.text(0.02, 0.02, 'Color Scale: Yellow (Low Heat Risk) → Red (High Heat Risk)', \n",
    "                transform=ax3.transAxes, fontsize=11, verticalalignment='bottom',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        ax3.axis('off')\n",
    "        plt.tight_layout()\n",
    "        panel3_path = Outputs_path / 'Figures' / 'panel3_urban_design.png'\n",
    "        plt.savefig(panel3_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Panel 3 saved\")\n",
    "\n",
    "        print(f\"\\n✓ Analysis complete. All maps saved to {Outputs_path / 'Figures'}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
